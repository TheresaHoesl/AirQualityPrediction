{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9e46aad",
   "metadata": {},
   "source": [
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 02: Daily Feature Pipeline for Air Quality (aqicn.org) and weather (openmeteo)</span>\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "1. Download and Parse Data\n",
    "2. Feature Group Insertion\n",
    "\n",
    "\n",
    "__This notebook should be scheduled to run daily__\n",
    "\n",
    "In the book, we use a GitHub Action stored here:\n",
    "[.github/workflows/air-quality-daily.yml](https://github.com/featurestorebook/mlfs-book/blob/main/.github/workflows/air-quality-daily.yml)\n",
    "\n",
    "However, you are free to use any Python Orchestration tool to schedule this program to run daily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe638c6",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7de2e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "from functions import util\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "import pytz\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6081d1",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç Get the Sensor URL, Country, City, Street names from Hopsworks </span>\n",
    "\n",
    "__Update the values in the cell below.__\n",
    "\n",
    "__These should be the same values as in notebook 1 - the feature backfill notebook__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b70cd57d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1159326\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"country\": \"austria\", \"city\": \"vienna\", \"street\": \"vienna-taborstra\\\\u00dfe-glockengasse\", \"aqicn_url\": \"https://api.waqi.info/feed/@2860\", \"latitude\": 48.21, \"longitude\": 16.37}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you haven't set the env variable 'HOPSWORKS_API_KEY', then uncomment the next line and enter your API key\n",
    "# with open('../data/hopsworks-api-key.txt', 'r') as file:\n",
    "#     os.environ[\"HOPSWORKS_API_KEY\"] = file.read().rstrip()\n",
    "\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store() \n",
    "secrets = util.secrets_api(project.name)\n",
    "\n",
    "# This line will fail if you have not registered the AQI_API_KEY as a secret in Hopsworks\n",
    "AQI_API_KEY = secrets.get_secret(\"AQI_API_KEY\").value\n",
    "location_str = secrets.get_secret(\"SENSOR_LOCATION_JSON\").value\n",
    "location = json.loads(location_str)\n",
    "\n",
    "country=location['country']\n",
    "city=location['city']\n",
    "street=location['street']\n",
    "aqicn_url=location['aqicn_url']\n",
    "latitude=location['latitude']\n",
    "longitude=location['longitude']\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "location_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caf9289",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ Get references to the Feature Groups </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66f5d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='air_quality',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "air_quality_lag_fg = fs.get_feature_group(\n",
    "    name='air_quality_with_rolling_window',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b6ce8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ffa41",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå´ Retrieve Today's Air Quality data (PM2.5) from the AQI API</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f681af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm25</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61.0</td>\n",
       "      <td>austria</td>\n",
       "      <td>vienna</td>\n",
       "      <td>vienna-taborstra√üe-glockengasse</td>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>https://api.waqi.info/feed/@2860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pm25  country    city                           street       date  \\\n",
       "0  61.0  austria  vienna  vienna-taborstra√üe-glockengasse 2024-11-13   \n",
       "\n",
       "                                url  \n",
       "0  https://api.waqi.info/feed/@2860  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "aq_today_df = util.get_pm25(aqicn_url, country, city, street, today, AQI_API_KEY)\n",
    "aq_today_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9e24eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   pm25     1 non-null      float32       \n",
      " 1   country  1 non-null      object        \n",
      " 2   city     1 non-null      object        \n",
      " 3   street   1 non-null      object        \n",
      " 4   date     1 non-null      datetime64[ns]\n",
      " 5   url      1 non-null      object        \n",
      "dtypes: datetime64[ns](1), float32(1), object(4)\n",
      "memory usage: 172.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "aq_today_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af845ab6",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå¶ Get Weather Forecast data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2ecb3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates 48.0¬∞N 16.5¬∞E\n",
      "Elevation 194.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.891343</td>\n",
       "      <td>328.240570</td>\n",
       "      <td>vienna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-14</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.323528</td>\n",
       "      <td>311.423584</td>\n",
       "      <td>vienna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-15</td>\n",
       "      <td>9.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.758419</td>\n",
       "      <td>321.044067</td>\n",
       "      <td>vienna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-16</td>\n",
       "      <td>9.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.893995</td>\n",
       "      <td>123.690102</td>\n",
       "      <td>vienna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-17</td>\n",
       "      <td>6.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.735060</td>\n",
       "      <td>171.253922</td>\n",
       "      <td>vienna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-11-18</td>\n",
       "      <td>10.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.610250</td>\n",
       "      <td>141.340164</td>\n",
       "      <td>vienna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-11-19</td>\n",
       "      <td>10.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.947083</td>\n",
       "      <td>128.829834</td>\n",
       "      <td>vienna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>13.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.161400</td>\n",
       "      <td>146.082535</td>\n",
       "      <td>vienna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-11-21</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11.620809</td>\n",
       "      <td>343.810699</td>\n",
       "      <td>vienna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-11-22</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.207634</td>\n",
       "      <td>287.447266</td>\n",
       "      <td>vienna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  temperature_2m_mean  precipitation_sum  wind_speed_10m_max  \\\n",
       "0 2024-11-13                 4.20                0.0            8.891343   \n",
       "1 2024-11-14                 7.25                0.0           16.323528   \n",
       "2 2024-11-15                 9.10                0.0           21.758419   \n",
       "3 2024-11-16                 9.65                0.0            3.893995   \n",
       "4 2024-11-17                 6.85                0.0            4.735060   \n",
       "5 2024-11-18                10.55                0.0            4.610250   \n",
       "6 2024-11-19                10.35                0.0           18.947083   \n",
       "7 2024-11-20                13.90                0.0           25.161400   \n",
       "8 2024-11-21                 5.80                0.1           11.620809   \n",
       "9 2024-11-22                 4.50                0.0           13.207634   \n",
       "\n",
       "   wind_direction_10m_dominant    city  \n",
       "0                   328.240570  vienna  \n",
       "1                   311.423584  vienna  \n",
       "2                   321.044067  vienna  \n",
       "3                   123.690102  vienna  \n",
       "4                   171.253922  vienna  \n",
       "5                   141.340164  vienna  \n",
       "6                   128.829834  vienna  \n",
       "7                   146.082535  vienna  \n",
       "8                   343.810699  vienna  \n",
       "9                   287.447266  vienna  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_df = util.get_hourly_weather_forecast(city, latitude, longitude)\n",
    "hourly_df = hourly_df.set_index('date')\n",
    "\n",
    "# We will only make 1 daily prediction, so we will replace the hourly forecasts with a single daily forecast\n",
    "# We only want the daily weather data, so only get weather at 12:00\n",
    "daily_df = hourly_df.between_time('11:59', '12:01')\n",
    "daily_df = daily_df.reset_index()\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date']).dt.date\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date'])\n",
    "daily_df['city'] = city\n",
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c563109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   date                         10 non-null     datetime64[ns]\n",
      " 1   temperature_2m_mean          10 non-null     float32       \n",
      " 2   precipitation_sum            10 non-null     float32       \n",
      " 3   wind_speed_10m_max           10 non-null     float32       \n",
      " 4   wind_direction_10m_dominant  10 non-null     float32       \n",
      " 5   city                         10 non-null     object        \n",
      "dtypes: datetime64[ns](1), float32(4), object(1)\n",
      "memory usage: 448.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "daily_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f5008",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#ff5f27;\">‚¨ÜÔ∏è Uploading new data to the Feature Store</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1eee28f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-13 19:26:34,653 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1159326/fs/1150029/fg/1338743\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c661d04d8cb4b82ac485398a391de39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/1 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1159326/jobs/named/air_quality_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x214769b7f70>,\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"pm25\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 500.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 662538\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 61.0,\n",
       "         \"element_count\": 1,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-11-13T06:26:34.000649Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 1,\n",
       "     \"successful_expectations\": 1,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"aq_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2024-11-13T19:26:34.652973+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"d00a0f38-a1ec-11ef-8199-f446376431c8\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20241113T182634.649963Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert new data\n",
    "air_quality_fg.insert(aq_today_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a04ec53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.41s) \n",
      "There are records from the last 3 days:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915f0def23e443c1b536e4d4c6f1df99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/1 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_with_rolling_window_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1159326/jobs/named/air_quality_with_rolling_window_1_offline_fg_materialization/executions\n"
     ]
    }
   ],
   "source": [
    "# Calculate date range for the last 3 days\n",
    "three_days_ago = datetime.datetime.now() - datetime.timedelta(days=3)\n",
    "three_days_ago = three_days_ago.replace(hour=0, minute=0, second=0, microsecond=0, tzinfo=pytz.UTC)\n",
    "\n",
    "# Read the air quality data into a DataFrame\n",
    "air_quality_df = air_quality_fg.read()\n",
    "\n",
    "# Ensure 'date' column is in datetime format, if not convert it\n",
    "if not pd.api.types.is_datetime64_any_dtype(air_quality_df['date']):\n",
    "    air_quality_df['date'] = pd.to_datetime(air_quality_df['date'])\n",
    "\n",
    "# Filter the data for the last 3 days\n",
    "three_days_data = air_quality_df[air_quality_df['date'] >= three_days_ago]\n",
    "\n",
    "# Sort by date for accurate rolling computation\n",
    "three_days_data = three_days_data.sort_values('date')\n",
    "\n",
    "# Calculate the rolling mean for a 3-day window for 'pm25'\n",
    "three_days_data['pm25_prev'] = (\n",
    "    three_days_data.set_index('date')['pm25']  # Set 'date' as index\n",
    "    .rolling('3D')  # Apply a 3-day rolling window\n",
    "    .mean()  # Calculate mean within the window\n",
    "    .reset_index(drop=True)  # Drop index to keep it consistent\n",
    ")\n",
    "\n",
    "# Check if any records exist for the last 3 days\n",
    "if not three_days_data.empty:\n",
    "    print(\"There are records from the last 3 days:\")\n",
    "    # If yes, prepare the data for insertion into the lagged feature group\n",
    "    prev_data = three_days_data['pm25_prev'].iloc[-1]\n",
    "    data_to_insert = pd.DataFrame({\n",
    "        'pm25':[np.float32(aq_today_df['pm25'].values[0])],\n",
    "        'pm25_prev': [prev_data],\n",
    "        'date': [datetime.datetime.now()],  # Include other necessary columns, like 'date'\n",
    "        'country': ['austria'],\n",
    "        'city': ['vienna'],\n",
    "        'street': ['vienna-taborstra√üe-glockengasse'],\n",
    "        'url': ['https://api.waqi.info/feed/@2860']\n",
    "    })\n",
    "    \n",
    "    # Insert the DataFrame into the feature group\n",
    "    air_quality_lag_fg.insert(data_to_insert)\n",
    "else:\n",
    "    print(\"No records for the last 3 days.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d491b0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-13 19:27:23,707 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1159326/fs/1150029/fg/1337716\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c087242b8cb84b8a9572c7185fb4f0e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/10 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_1_offline_fg_materialization\n"
     ]
    },
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1159326/jobs/weather_1_offline_fg_materialization/executions). Server response: \nHTTP code: 400, HTTP reason: Bad Request, body: b'{\"errorCode\":130040,\"usrMsg\":\"Parallel executions quota reached for Project: ID2223_Hosl_Ghosh Current 5 Max: 5\",\"devMsg\":\"Parallel executions quota reached for Project: ID2223_Hosl_Ghosh Current 5 Max: 5\",\"errorMsg\":\"Job reached the maximum number of executions.\"}', error code: 130040, error msg: Job reached the maximum number of executions., user msg: Parallel executions quota reached for Project: ID2223_Hosl_Ghosh Current 5 Max: 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Insert new data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mweather_fg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdaily_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\there\\anaconda3\\envs\\airquality\\lib\\site-packages\\hsfs\\feature_group.py:2528\u001b[0m, in \u001b[0;36mFeatureGroup.insert\u001b[1;34m(self, features, overwrite, operation, storage, write_options, validation_options, save_code, wait)\u001b[0m\n\u001b[0;32m   2525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_for_job\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m write_options:\n\u001b[0;32m   2526\u001b[0m     write_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_for_job\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m wait\n\u001b[1;32m-> 2528\u001b[0m job, ge_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_group_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2529\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2531\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2532\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_report\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalidation_options\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2536\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_code \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m   2538\u001b[0m     ge_report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m ge_report\u001b[38;5;241m.\u001b[39mingestion_result \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINGESTED\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2539\u001b[0m ):\n\u001b[0;32m   2540\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_code_engine\u001b[38;5;241m.\u001b[39msave_code(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\there\\anaconda3\\envs\\airquality\\lib\\site-packages\\hsfs\\core\\feature_group_engine.py:132\u001b[0m, in \u001b[0;36mFeatureGroupEngine.insert\u001b[1;34m(self, feature_group, feature_dataframe, overwrite, operation, storage, write_options, validation_options)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m overwrite:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_group_api\u001b[38;5;241m.\u001b[39mdelete_content(feature_group)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 132\u001b[0m     \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbulk_insert\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monline_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffline_write_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43monline_write_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    141\u001b[0m     ge_report,\n\u001b[0;32m    142\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\there\\anaconda3\\envs\\airquality\\lib\\site-packages\\hsfs\\engine\\python.py:593\u001b[0m, in \u001b[0;36mEngine.save_dataframe\u001b[1;34m(self, feature_group, dataframe, operation, online_enabled, storage, offline_write_options, online_write_options, validation_id)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_dataframe\u001b[39m(\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    580\u001b[0m     feature_group: FeatureGroup,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    587\u001b[0m     validation_id: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    588\u001b[0m ):\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    590\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(feature_group, ExternalFeatureGroup)\n\u001b[0;32m    591\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m feature_group\u001b[38;5;241m.\u001b[39monline_enabled\n\u001b[0;32m    592\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m feature_group\u001b[38;5;241m.\u001b[39mstream:\n\u001b[1;32m--> 593\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_dataframe_kafka\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffline_write_options\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    597\u001b[0m         \u001b[38;5;66;03m# for backwards compatibility\u001b[39;00m\n\u001b[0;32m    598\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegacy_save_dataframe(\n\u001b[0;32m    599\u001b[0m             feature_group,\n\u001b[0;32m    600\u001b[0m             dataframe,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m             validation_id,\n\u001b[0;32m    607\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\there\\anaconda3\\envs\\airquality\\lib\\site-packages\\hsfs\\engine\\python.py:1106\u001b[0m, in \u001b[0;36mEngine._write_dataframe_kafka\u001b[1;34m(self, feature_group, dataframe, offline_write_options)\u001b[0m\n\u001b[0;32m   1104\u001b[0m         initial_check_point \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;66;03m# provide the initial_check_point as it will reduce the read amplification of materialization job\u001b[39;00m\n\u001b[1;32m-> 1106\u001b[0m     \u001b[43mfeature_group\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaterialization_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_group\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaterialization_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefaultArgs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_check_point\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mawait_termination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffline_write_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwait_for_job\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature_group, ExternalFeatureGroup):\n\u001b[0;32m   1112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\there\\anaconda3\\envs\\airquality\\lib\\site-packages\\hsfs\\core\\job.py:118\u001b[0m, in \u001b[0;36mJob.run\u001b[1;34m(self, args, await_termination)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run the job.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03mRuns the job, by default awaiting its completion.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    await_termination: Identifies if the client should wait for the job to complete, defaults to True.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLaunching job: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_job_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob started successfully, you can follow the progress at \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    121\u001b[0m         util\u001b[38;5;241m.\u001b[39mget_job_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhref)\n\u001b[0;32m    122\u001b[0m     )\n\u001b[0;32m    123\u001b[0m )\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_job(await_termination\u001b[38;5;241m=\u001b[39mawait_termination)\n",
      "File \u001b[1;32mc:\\Users\\there\\anaconda3\\envs\\airquality\\lib\\site-packages\\hsfs\\core\\job_api.py:39\u001b[0m, in \u001b[0;36mJobApi.launch\u001b[1;34m(self, name, args)\u001b[0m\n\u001b[0;32m     36\u001b[0m _client \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_instance()\n\u001b[0;32m     37\u001b[0m path_params \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m\"\u001b[39m, _client\u001b[38;5;241m.\u001b[39m_project_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjobs\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecutions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 39\u001b[0m \u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\there\\anaconda3\\envs\\airquality\\lib\\site-packages\\hsfs\\decorators.py:35\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[1;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst\u001b[38;5;241m.\u001b[39m_connected:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\there\\anaconda3\\envs\\airquality\\lib\\site-packages\\hsfs\\client\\base.py:176\u001b[0m, in \u001b[0;36mClient._send_request\u001b[1;34m(self, method, path_params, query_params, headers, data, stream, files)\u001b[0m\n\u001b[0;32m    171\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_token_expired(\n\u001b[0;32m    172\u001b[0m         request, stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTOKEN_EXPIRED_RETRY_INTERVAL, \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    173\u001b[0m     )\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mRestAPIError(url, response)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[1;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1159326/jobs/weather_1_offline_fg_materialization/executions). Server response: \nHTTP code: 400, HTTP reason: Bad Request, body: b'{\"errorCode\":130040,\"usrMsg\":\"Parallel executions quota reached for Project: ID2223_Hosl_Ghosh Current 5 Max: 5\",\"devMsg\":\"Parallel executions quota reached for Project: ID2223_Hosl_Ghosh Current 5 Max: 5\",\"errorMsg\":\"Job reached the maximum number of executions.\"}', error code: 130040, error msg: Job reached the maximum number of executions., user msg: Parallel executions quota reached for Project: ID2223_Hosl_Ghosh Current 5 Max: 5"
     ]
    }
   ],
   "source": [
    "# Insert new data\n",
    "weather_fg.insert(daily_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e9e2d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 03: Training Pipeline\n",
    " </span> \n",
    "\n",
    "In the following notebook you will read from a feature group and create training dataset within the feature store\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airquality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
